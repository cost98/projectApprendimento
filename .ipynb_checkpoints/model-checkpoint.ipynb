{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "ca0e1f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "11525bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>accel_x</th>\n",
       "      <th>accel_y</th>\n",
       "      <th>accel_z</th>\n",
       "      <th>accel_norm</th>\n",
       "      <th>gyro_x</th>\n",
       "      <th>gyro_y</th>\n",
       "      <th>gyro_z</th>\n",
       "      <th>subject</th>\n",
       "      <th>activity</th>\n",
       "      <th>trial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.036789</td>\n",
       "      <td>0.485275</td>\n",
       "      <td>0.345870</td>\n",
       "      <td>1.195847</td>\n",
       "      <td>0.316738</td>\n",
       "      <td>0.778180</td>\n",
       "      <td>1.082764</td>\n",
       "      <td>1</td>\n",
       "      <td>dws</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.972504</td>\n",
       "      <td>0.692962</td>\n",
       "      <td>0.082611</td>\n",
       "      <td>1.196990</td>\n",
       "      <td>0.842032</td>\n",
       "      <td>0.424446</td>\n",
       "      <td>0.643574</td>\n",
       "      <td>1</td>\n",
       "      <td>dws</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.770325</td>\n",
       "      <td>0.784256</td>\n",
       "      <td>-0.200515</td>\n",
       "      <td>1.117437</td>\n",
       "      <td>-0.138143</td>\n",
       "      <td>-0.040741</td>\n",
       "      <td>0.343563</td>\n",
       "      <td>1</td>\n",
       "      <td>dws</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.752320</td>\n",
       "      <td>0.784576</td>\n",
       "      <td>0.053818</td>\n",
       "      <td>1.088320</td>\n",
       "      <td>-0.025005</td>\n",
       "      <td>-1.048717</td>\n",
       "      <td>0.035860</td>\n",
       "      <td>1</td>\n",
       "      <td>dws</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.959503</td>\n",
       "      <td>1.001206</td>\n",
       "      <td>-0.102829</td>\n",
       "      <td>1.390551</td>\n",
       "      <td>0.114253</td>\n",
       "      <td>-0.912890</td>\n",
       "      <td>0.047341</td>\n",
       "      <td>1</td>\n",
       "      <td>dws</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840560</th>\n",
       "      <td>785</td>\n",
       "      <td>-0.446106</td>\n",
       "      <td>1.299194</td>\n",
       "      <td>1.412735</td>\n",
       "      <td>1.970466</td>\n",
       "      <td>-1.099007</td>\n",
       "      <td>0.677079</td>\n",
       "      <td>-0.248915</td>\n",
       "      <td>24</td>\n",
       "      <td>jog</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840561</th>\n",
       "      <td>786</td>\n",
       "      <td>0.453796</td>\n",
       "      <td>0.242035</td>\n",
       "      <td>-1.395951</td>\n",
       "      <td>1.487680</td>\n",
       "      <td>1.002112</td>\n",
       "      <td>0.500122</td>\n",
       "      <td>3.548562</td>\n",
       "      <td>24</td>\n",
       "      <td>jog</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840562</th>\n",
       "      <td>787</td>\n",
       "      <td>0.663437</td>\n",
       "      <td>1.032440</td>\n",
       "      <td>-1.243103</td>\n",
       "      <td>1.746822</td>\n",
       "      <td>2.195139</td>\n",
       "      <td>0.520332</td>\n",
       "      <td>7.577656</td>\n",
       "      <td>24</td>\n",
       "      <td>jog</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840563</th>\n",
       "      <td>788</td>\n",
       "      <td>0.618576</td>\n",
       "      <td>1.973877</td>\n",
       "      <td>-1.455643</td>\n",
       "      <td>2.529372</td>\n",
       "      <td>0.700754</td>\n",
       "      <td>-4.660940</td>\n",
       "      <td>8.016102</td>\n",
       "      <td>24</td>\n",
       "      <td>jog</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840564</th>\n",
       "      <td>789</td>\n",
       "      <td>0.128509</td>\n",
       "      <td>4.968110</td>\n",
       "      <td>0.069259</td>\n",
       "      <td>4.970254</td>\n",
       "      <td>2.142517</td>\n",
       "      <td>-4.579572</td>\n",
       "      <td>5.868259</td>\n",
       "      <td>24</td>\n",
       "      <td>jog</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>840565 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0   accel_x   accel_y   accel_z  accel_norm    gyro_x  \\\n",
       "0                0  1.036789  0.485275  0.345870    1.195847  0.316738   \n",
       "1                1  0.972504  0.692962  0.082611    1.196990  0.842032   \n",
       "2                2  0.770325  0.784256 -0.200515    1.117437 -0.138143   \n",
       "3                3  0.752320  0.784576  0.053818    1.088320 -0.025005   \n",
       "4                4  0.959503  1.001206 -0.102829    1.390551  0.114253   \n",
       "...            ...       ...       ...       ...         ...       ...   \n",
       "840560         785 -0.446106  1.299194  1.412735    1.970466 -1.099007   \n",
       "840561         786  0.453796  0.242035 -1.395951    1.487680  1.002112   \n",
       "840562         787  0.663437  1.032440 -1.243103    1.746822  2.195139   \n",
       "840563         788  0.618576  1.973877 -1.455643    2.529372  0.700754   \n",
       "840564         789  0.128509  4.968110  0.069259    4.970254  2.142517   \n",
       "\n",
       "          gyro_y    gyro_z  subject activity  trial  \n",
       "0       0.778180  1.082764        1      dws      1  \n",
       "1       0.424446  0.643574        1      dws      1  \n",
       "2      -0.040741  0.343563        1      dws      1  \n",
       "3      -1.048717  0.035860        1      dws      1  \n",
       "4      -0.912890  0.047341        1      dws      1  \n",
       "...          ...       ...      ...      ...    ...  \n",
       "840560  0.677079 -0.248915       24      jog     16  \n",
       "840561  0.500122  3.548562       24      jog     16  \n",
       "840562  0.520332  7.577656       24      jog     16  \n",
       "840563 -4.660940  8.016102       24      jog     16  \n",
       "840564 -4.579572  5.868259       24      jog     16  \n",
       "\n",
       "[840565 rows x 11 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"C:/Users/STRUSI Cosimo/Documents/Uni/Consegna Ramat/projectApprendimento/TrainData1.csv\")\n",
    "test = pd.read_csv(\"C:/Users/STRUSI Cosimo/Documents/Uni/Consegna Ramat/projectApprendimento/TestData1.csv\")\n",
    "val = pd.read_csv(\"C:/Users/STRUSI Cosimo/Documents/Uni/Consegna Ramat/projectApprendimento/ValData1.csv\")\n",
    "train\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d166441",
   "metadata": {},
   "source": [
    "Preprocessing : scalatura dati di training e test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "8417b442",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_columns = ['accel_x','accel_y','accel_z','accel_norm',\n",
    "'gyro_x','gyro_y','gyro_z']\n",
    "\n",
    "scaler = StandardScaler() \n",
    "\n",
    "train_sc = train[scale_columns]\n",
    "test_sc = test[scale_columns]\n",
    "val_sc = val[scale_columns]\n",
    "\n",
    "scaler = scaler.fit(train_sc[scale_columns]) # calcola il massimo e il minimo\n",
    "scaler.fit(train_sc) \n",
    "train_sc = scaler.transform(train_sc) \n",
    "test_sc = scaler.transform(test_sc)\n",
    "val_sc = scaler.transform(val_sc)\n",
    "\n",
    "train_sc =pd.DataFrame(train_sc,columns = scale_columns)\n",
    "test_sc =pd.DataFrame(test_sc,columns = scale_columns)\n",
    "val_sc =pd.DataFrame(val_sc,columns = scale_columns)\n",
    "\n",
    "train_sc['subject'] = train['subject']\n",
    "test_sc['subject'] = test['subject']\n",
    "val_sc['subject'] = val['subject']\n",
    "\n",
    "train_sc['activity'] = train['activity']\n",
    "test_sc['activity'] = test['activity']\n",
    "val_sc['activity'] = val['activity']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a593eb",
   "metadata": {},
   "source": [
    "Preprocessing - create timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "10d04e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# funzione per organizzare il dataset\n",
    "def create_dataset(X, y, time_steps, step):\n",
    "    Xs, ys = [], [] # inizializzo due liste vuote\n",
    "    if step !=0:\n",
    "      for i in range(0, len(X) - time_steps, step): # ciclo for che parte da zero alla lughezza di (X-time_steps), con passo di step\n",
    "          v = X.iloc[i:(i + time_steps)].values # del DataFrame prendo i valori che vanno da i fino ad i+time_steps\n",
    "          labels = y.iloc[i: i + time_steps] # stessa cosa con le labels\n",
    "          Xs.append(v) # aggiunge un item in coda alla lista\n",
    "          ys.append(stats.mode(labels)[0][0]) # ad ogni finestra corrisponderÃ  un valore di una classe\n",
    "    else:\n",
    "      for i in range(0, len(X) - time_steps, time_steps): # ciclo for che parte da zero alla lughezza di (X-time_steps), con passo di  time_steps\n",
    "          v = X.iloc[i:(i + time_steps)].values # del DataFrame prendo i valori che vanno da i fino ad i+time_steps\n",
    "          labels = y.iloc[i: i + time_steps] # stessa cosa con le labels\n",
    "          Xs.append(v) # aggiunge un item in coda alla lista\n",
    "          ys.append(stats.mode(labels)[0][0]) # ad ogni finestra corrisponderÃ  un valore di una classe\n",
    "    return np.array(Xs), np.array(ys).reshape(-1, 1) # output della funzione resistuisce Xs come un array e Ys come un vettore\n",
    "\n",
    "train = train_sc\n",
    "test = test_sc\n",
    "val = val_sc\n",
    "\n",
    "TIME_STEPS = 200\n",
    "STEP = 40\n",
    "# richiamo la funzione per creare X_train e Y_train\n",
    "X_train, Y_train = create_dataset(\n",
    "    train[ ['accel_x','accel_y','accel_z','accel_norm',\n",
    "'gyro_x','gyro_y','gyro_z']],\n",
    "    train.activity,\n",
    "    TIME_STEPS,\n",
    "    STEP\n",
    ")\n",
    "\n",
    "TIME_STEPS = 200\n",
    "STEP = 0\n",
    "# richiamo la funzione per creare X_val e Y_val\n",
    "\n",
    "X_val, Y_val = create_dataset(\n",
    "    val[ ['accel_x','accel_y','accel_z','accel_norm',\n",
    "'gyro_x','gyro_y','gyro_z']],\n",
    "    val.activity,\n",
    "    TIME_STEPS,\n",
    "    STEP\n",
    ")\n",
    "\n",
    "TIME_STEPS = 200\n",
    "STEP = 0\n",
    "# richiamo la funzione per creare X_test e Y_test\n",
    "\n",
    "X_test, Y_test = create_dataset(\n",
    "    test[ ['accel_x','accel_y','accel_z','accel_norm',\n",
    "'gyro_x','gyro_y','gyro_z']],\n",
    "    test.activity,\n",
    "    TIME_STEPS,\n",
    "    STEP\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae7651f",
   "metadata": {},
   "source": [
    "Preprocessing - one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "69e6f78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22484, 6)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = Y_train.reshape((-1))\n",
    "y_test = Y_test.reshape((-1))\n",
    "y_val = Y_val.reshape((-1))\n",
    "\n",
    "# One Hot encoding \n",
    "y_train = pd.get_dummies(y_train)\n",
    "y_test = pd.get_dummies(y_test)\n",
    "y_val = pd.get_dummies(y_val)\n",
    "\n",
    "X_trainNew = np.vstack([X_train, X_val]) # generate an error\n",
    "X_trainNew.shape\n",
    "y_trainNew  = np.vstack([y_train, y_val]) # generate an error\n",
    "y_trainNew.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e0323f",
   "metadata": {},
   "source": [
    "First model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ba0f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "329/329 [==============================] - 215s 520ms/step - loss: 1.3708 - accuracy: 0.4637 - val_loss: 0.9482 - val_accuracy: 0.6275\n",
      "Epoch 2/15\n",
      "329/329 [==============================] - 183s 550ms/step - loss: 0.7630 - accuracy: 0.7071 - val_loss: 0.6538 - val_accuracy: 0.7374\n",
      "Epoch 3/15\n",
      "329/329 [==============================] - 155s 471ms/step - loss: 0.6617 - accuracy: 0.7447 - val_loss: 0.6126 - val_accuracy: 0.7897\n",
      "Epoch 4/15\n",
      "329/329 [==============================] - 139s 419ms/step - loss: 0.9445 - accuracy: 0.6524 - val_loss: 0.8254 - val_accuracy: 0.6906\n",
      "Epoch 5/15\n",
      "301/329 [==========================>...] - ETA: 11s - loss: 0.7026 - accuracy: 0.7228"
     ]
    }
   ],
   "source": [
    "# Modello\n",
    "model = keras.Sequential()\n",
    "model.add(LSTM(100, input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "# Compilazione del modello\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate= 1e-4), metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val),  batch_size=64, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d3519d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102a7d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot(ax=axs)\n",
    "history_df.loc[:, ['accuracy', 'val_accuracy']].plot(ax=axs)\n",
    "\n",
    "axs.set_xlabel(\"epoca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66534853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modello allenato su tutti i dati di training e validation\n",
    "model = keras.Sequential()\n",
    "model.add(LSTM(100, input_shape=(X_trainNew.shape[1],X_trainNew.shape[2])))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(y_trainNew.shape[1], activation='softmax'))\n",
    "\n",
    "# Compilazione del modello\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate= 1e-4), metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_trainNew, y_trainNew,  batch_size=64, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93612f5a",
   "metadata": {},
   "source": [
    "First model - Evaluate first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5105684",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,y_test)\n",
    "\n",
    "# Test del modello allenato\n",
    "y_hat = model.predict(X_test) # output dell'ultimo strato del modello\n",
    "predict = np.argmax(y_hat, axis=1) # ricodifico i valori predetti\n",
    "label = np.argmax(y_test.values, axis=1) # ricodifico i valori veri\n",
    "\n",
    "\n",
    "model.save(\"modelloLSTM1\")\n",
    "\n",
    "\n",
    "\n",
    "def statistical_measures(predict, label):  \n",
    "  cnf_matrix = confusion_matrix(label, predict)\n",
    "  # falsi positivi\n",
    "  FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix) \n",
    "  # falsi negativi\n",
    "  FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
    "  # veri positivi\n",
    "  TP = np.diag(cnf_matrix)\n",
    "  # veri negativi\n",
    "  TN = cnf_matrix.sum() - (FP + FN + TP)\n",
    "  # assegno il tipo di variabile\n",
    "  FP = FP.astype(float)\n",
    "  FN = FN.astype(float)\n",
    "  TP = TP.astype(float)\n",
    "  TN = TN.astype(float)\n",
    "  # Sensitivity, hit rate, recall, or true positive rate\n",
    "  TPR = TP / (TP + FN)\n",
    "  # Specificity or true negative rate\n",
    "  TNR = TN / (TN + FP)\n",
    "  # Precision or positive predictive value\n",
    "  PPV = TP / (TP + FP)\n",
    "  # Negative predictive value\n",
    "  NPV = TN / (TN + FN)\n",
    "  # Fall out or false positive rate\n",
    "  FPR = FP / (FP + TN)\n",
    "  # False negative rate\n",
    "  FNR = FN / (TP + FN)\n",
    "  # False discovery rate\n",
    "  FDR = FP / (TP + FP)\n",
    "  # Overall accuracy for each class\n",
    "  ACC = (TP + TN) / (TP + FP + FN + TN)\n",
    "  ACC_TOT = (cnf_matrix.diagonal()).sum() / len(label)\n",
    "  return ACC_TOT, ACC, PPV, TPR # output\n",
    "\n",
    "acc_tot, acc_classes, precision_classes, recall_classes = statistical_measures(predict, label) # richiamo la funzione\n",
    "print(acc_tot, acc_classes, precision_classes, recall_classes)\n",
    "\n",
    "cm = (confusion_matrix(label, predict))\n",
    "true_labels = np.unique(Y_test) # creo il vettore delle classi possibili\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_cm = pd.DataFrame(cm/np.sum(cm, axis=1), index = [i for i in true_labels], columns = [i for i in true_labels]) # percetuali di quanti esempi per classe sono stati classificati correttamente\n",
    "df_cm.head()\n",
    "\n",
    "plt.figure(figsize = (12,12)) # size della figura\n",
    "sn.heatmap(df_cm, annot=True, fmt='.2%',cbar=False, linewidths=.8, square=True, xticklabels=true_labels,\n",
    "            yticklabels=true_labels ) # confusion matrix\n",
    "plt.title('Confusion Matrix', fontsize=22)\n",
    "plt.ylabel('Target', fontsize=20)\n",
    "plt.xlabel('Output', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b93e9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(X_trainNew) # output dell'ultimo strato del modello\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6491ef14",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = np.argmax(y_hat, axis=1) # ricodifico i valori predetti\n",
    "label = np.argmax(y_trainNew, axis=1) # ricodifico i valori veri\n",
    "\n",
    "acc_tot, acc_classes, precision_classes, recall_classes = statistical_measures(predict, label) # richiamo la funzione\n",
    "print(acc_tot, acc_classes, precision_classes, recall_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cae6c65",
   "metadata": {},
   "source": [
    "Second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b5991e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "model = keras.Sequential()\n",
    "model.add(LSTM(units=100, input_shape=(X_train.shape[1],X_train.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(units=50, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(25))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate= 1e-4), metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val),  batch_size=64, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e2d3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot(ax=axs)\n",
    "history_df.loc[:, ['accuracy', 'val_accuracy']].plot(ax=axs)\n",
    "\n",
    "axs.set_xlabel(\"epoca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0b2ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modello allenato su tutti i dati \n",
    "model = keras.Sequential()\n",
    "model.add(LSTM(100, input_shape=(X_trainNew.shape[1],X_trainNew.shape[2])))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(y_trainNew.shape[1], activation='softmax'))\n",
    "\n",
    "# Compilazione del modello\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate= 1e-4), metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_trainNew, y_trainNew,  batch_size=64, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fc0efc",
   "metadata": {},
   "source": [
    "Second modelEvaluate second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c298583a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,y_test)\n",
    "# Test del modello allenato\n",
    "y_hat = model.predict(X_test) # output dell'ultimo strato del modello\n",
    "predict = np.argmax(y_hat, axis=1) # ricodifico i valori predetti\n",
    "label = np.argmax(y_test.values, axis=1) # ricodifico i valori veri\n",
    "\n",
    "\n",
    "model.save(\"modelloLSTM2\")\n",
    "\n",
    "\n",
    "acc_tot, acc_classes, precision_classes, recall_classes = statistical_measures(predict, label) # richiamo la funzione\n",
    "print(acc_tot, acc_classes, precision_classes, recall_classes)\n",
    "\n",
    "cm = (confusion_matrix(label, predict))\n",
    "true_labels = np.unique(Y_test) # creo il vettore delle classi possibili\n",
    "\n",
    "\n",
    "df_cm = pd.DataFrame(cm/np.sum(cm, axis=1), index = [i for i in true_labels], columns = [i for i in true_labels]) # percetuali di quanti esempi per classe sono stati classificati correttamente\n",
    "df_cm.head()\n",
    "\n",
    "plt.figure(figsize = (12,12)) # size della figura\n",
    "sn.heatmap(df_cm, annot=True, fmt='.2%',cbar=False, linewidths=.8, square=True, xticklabels=true_labels,\n",
    "            yticklabels=true_labels ) # confusion matrix\n",
    "plt.title('Confusion Matrix', fontsize=22)\n",
    "plt.ylabel('Target', fontsize=20)\n",
    "plt.xlabel('Output', fontsize=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
